{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c22c82a-d85d-4330-800c-186432417acc",
   "metadata": {},
   "source": [
    "EXPLICACION UNO: Se definen librerías de pandas y numpy, así como de sklearn y mlxtend.\n",
    "Abrimos la base de datos y armamos una vista corta para asegurarnos de que la información llegó completa.\n",
    "Verificamos el tamaño, dimensiones, y revisamos el muestreo de la información con la función .shape y .columns e imprimimos las primeras 5 filas de la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "94370369-0ed2-4a8a-8181-5b431db1d0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 12)\n",
      "Index(['acidezFija', 'acidezVolatil', 'acidoCitrico', 'azucarResidual',\n",
      "       'cloruros', 'dioxidoAzufreLibre', 'dioxidoAzufreTotal', 'densidad',\n",
      "       'pH', 'sulfatos', 'alcohol', 'calidad'],\n",
      "      dtype='object')\n",
      "   acidezFija  acidezVolatil  acidoCitrico  azucarResidual  cloruros  \\\n",
      "0         7.4           0.70          0.00             1.9     0.076   \n",
      "1         7.8           0.88          0.00             2.6     0.098   \n",
      "2         7.8           0.76          0.04             2.3     0.092   \n",
      "3        11.2           0.28          0.56             1.9     0.075   \n",
      "4         7.4           0.70          0.00             1.9     0.076   \n",
      "\n",
      "   dioxidoAzufreLibre  dioxidoAzufreTotal  densidad    pH  sulfatos  alcohol  \\\n",
      "0                11.0                34.0    0.9978  3.51      0.56      9.4   \n",
      "1                25.0                67.0    0.9968  3.20      0.68      9.8   \n",
      "2                15.0                54.0    0.9970  3.26      0.65      9.8   \n",
      "3                17.0                60.0    0.9980  3.16      0.58      9.8   \n",
      "4                11.0                34.0    0.9978  3.51      0.56      9.4   \n",
      "\n",
      "   calidad  \n",
      "0        5  \n",
      "1        5  \n",
      "2        5  \n",
      "3        6  \n",
      "4        5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "\n",
    "df=pd.read_csv(\"VinoTinto.csv\")\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a3b4d8-e688-40d9-9ac6-03a5981360f4",
   "metadata": {},
   "source": [
    "EXPLICACION DOS: Aquí separamos el dataset en dos subconjuntos sin superposición, uno para aprender (train) y otro para comprobar(test); se dividen en 80/20,con la funcion de .sample y se agrega la fraccion 0.8.\n",
    "Imprimimos en consola las dimensiones de train y test, asegurandonos que con la suma de ambas sean el total de la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1d5b6ef8-7bd3-43eb-b5c8-c39095df5048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1279, 12)\n",
      "Test: (320, 12)\n",
      "Suma train+test: 1599\n",
      "      acidezFija  acidezVolatil  acidoCitrico  azucarResidual  cloruros  \\\n",
      "186          7.4           0.39          0.48            2.00     0.082   \n",
      "1289         7.0           0.60          0.30            4.50     0.068   \n",
      "1471         6.7           0.70          0.08            3.75     0.067   \n",
      "205         12.8           0.30          0.74            2.60     0.095   \n",
      "639          8.9           0.29          0.35            1.90     0.067   \n",
      "1154         6.6           0.58          0.00            2.20     0.100   \n",
      "179          8.8           0.61          0.14            2.40     0.067   \n",
      "1224        12.6           0.39          0.49            2.50     0.080   \n",
      "116          8.3           0.54          0.28            1.90     0.077   \n",
      "1406         8.2           0.24          0.34            5.10     0.062   \n",
      "549          9.0           0.53          0.49            1.90     0.171   \n",
      "572         10.2           0.24          0.49            2.40     0.075   \n",
      "430         10.5           0.24          0.47            2.10     0.066   \n",
      "767          7.5           0.60          0.32            2.70     0.103   \n",
      "264         12.5           0.56          0.49            2.40     0.064   \n",
      "\n",
      "      dioxidoAzufreLibre  dioxidoAzufreTotal  densidad    pH  sulfatos  \\\n",
      "186                 14.0                67.0   0.99720  3.34      0.55   \n",
      "1289                20.0               110.0   0.99914  3.30      1.17   \n",
      "1471                 8.0                16.0   0.99334  3.43      0.52   \n",
      "205                  9.0                28.0   0.99940  3.20      0.77   \n",
      "639                 25.0                57.0   0.99700  3.18      1.36   \n",
      "1154                50.0                63.0   0.99544  3.59      0.68   \n",
      "179                 10.0                42.0   0.99690  3.19      0.59   \n",
      "1224                 8.0                20.0   0.99920  3.07      0.82   \n",
      "116                 11.0                40.0   0.99780  3.39      0.61   \n",
      "1406                 8.0                22.0   0.99740  3.22      0.94   \n",
      "549                  6.0                25.0   0.99750  3.27      0.61   \n",
      "572                 10.0                28.0   0.99780  3.14      0.61   \n",
      "430                  6.0                24.0   0.99780  3.15      0.90   \n",
      "767                 13.0                98.0   0.99938  3.45      0.62   \n",
      "264                  5.0                27.0   0.99990  3.08      0.87   \n",
      "\n",
      "      alcohol  calidad  \n",
      "186       9.2        5  \n",
      "1289     10.2        5  \n",
      "1471     12.6        5  \n",
      "205      10.8        7  \n",
      "639      10.3        6  \n",
      "1154     11.4        6  \n",
      "179       9.5        5  \n",
      "1224     10.3        6  \n",
      "116      10.0        6  \n",
      "1406     10.9        6  \n",
      "549       9.4        6  \n",
      "572      10.4        5  \n",
      "430      11.0        7  \n",
      "767       9.5        5  \n",
      "264      10.9        5  \n"
     ]
    }
   ],
   "source": [
    "train=df.sample(frac=0.8)\n",
    "test=df.drop(train.index)\n",
    "print(\"Train:\",train.shape)\n",
    "print(\"Test:\",test.shape)\n",
    "sum=train.shape[0]+test.shape[0]\n",
    "print(\"Suma train+test:\",sum)\n",
    "print(train.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6686c93-e822-4bff-a8c2-e53691034950",
   "metadata": {},
   "source": [
    "EXPLICACION TRES: Dropeamos el dato de calidad, pues será el dato a predecir, y creamos un modelo lineal.\n",
    "Configuramos la selección hacia adelante,con la función de sfs que forward=True empieza vacío y va agregando variables una a una; k_features=(2,8) buscará el mejor subconjunto de entre 2 y 8 variables.\n",
    "R2 nos mide la calidad de cada conjunto.\n",
    "cv=10 usa validación cruzada, repartiendo los datos en 10 partes, entrena 9 y valida en 1, repite y promedia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "537941a3-b034-486d-95e4-f2abb265f800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas (Forward): ['acidezVolatil', 'cloruros', 'dioxidoAzufreLibre', 'dioxidoAzufreTotal', 'pH', 'sulfatos', 'alcohol']\n"
     ]
    }
   ],
   "source": [
    "Xtrain = train.drop('calidad', axis=1)\n",
    "ytrain = train['calidad']\n",
    "\n",
    "linearR = LinearRegression()\n",
    "\n",
    "sfs_forward = sfs(linearR,k_features=(2, 8),forward=True,floating=False,scoring='r2',cv=10,n_jobs=-1)\n",
    "\n",
    "sfs_forward = sfs_forward.fit(Xtrain, ytrain)\n",
    "feat_forward = list(sfs_forward.k_feature_names_)\n",
    "print(\"Características seleccionadas (Forward):\", feat_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbb40f4-5ea6-4bd6-8ede-983f4466793e",
   "metadata": {},
   "source": [
    "EXPLICACION CUATRO: Definimos en XtrainForward el feat_forward que solo toma las columnas que el algoritmo Forwrad seleccionó como relevantes.\n",
    "Con linearR.fit ajustamos de nuevo los coeficientes de beta, pero ahora usando solo las variables forward.\n",
    "En ypredForward el modelo genera las predicciones de calidad sobre el conjunto de prueba. Como las variables de entrada ahora son distintas, las predicciones pueden diferir respecto al modelo original con todas las variables.\n",
    "Y por último calculamos el R2 con las predicciones nuevas, esto nos ayuda a medir que tan bien es el subconjunto eelgido por Forward, explicando la variabilidad de la calidad en datos no vistos.\n",
    "Comparamos el r2Forward contra el R2 del modelo base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "34d3aa69-9ced-4378-9b86-eca3a956ba80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² del modelo Forward: 0.466134238113042\n"
     ]
    }
   ],
   "source": [
    "XtrainForward = Xtrain[feat_forward]\n",
    "XtestForward  = Xtest[feat_forward]\n",
    "\n",
    "linearR.fit(XtrainForward, ytrain)\n",
    "ypredForward = linearR.predict(XtestForward)\n",
    "\n",
    "r2Forward = r2_score(ytest, ypredForward)\n",
    "print(\"R² del modelo Forward:\", r2Forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a0081d-85d3-4f30-9c0f-b67ed0cd12a5",
   "metadata": {},
   "source": [
    "EXPLICACION CINCO: Creamos otro sfs pero ahora con forward=False, es decir, backward, este empieza con todas las variables candidatas y va eliminando una a una las que menos aportan.\n",
    "k_features=(2,5), dice que busque el mejor subconjunto entre 2 y 5 variables.\n",
    "scoring=r2 revisa la calidad de cada subconjunto y se mide con el coeficiente de determinación.\n",
    "Luego en el segundo sfs_backward, no empezamos desde las columnas orignales, sino de las que ya se seleccionaron por Forward, a partir de este conjunto el Backward prueba quitando variables de una en una, siempre evaluando el R2 en validación cruzada, hasta llegar al subconjunto mas compacto.\n",
    "Al final k_feature_names_ nos regresa el nombre exacto de las variables que sobrevivieron al proceso de eliminación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "677ae2ac-9012-43e4-b625-58fff387ff70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas (Backward desde Forward): ['acidezVolatil', 'cloruros', 'dioxidoAzufreTotal', 'sulfatos', 'alcohol']\n"
     ]
    }
   ],
   "source": [
    "sfs_backward = sfs(estimator=linearR,k_features=(2, 5),forward=False,floating=False,scoring='r2',cv=10,n_jobs=-1)\n",
    "\n",
    "sfs_backward = sfs_backward.fit(Xtrain[feat_forward], ytrain)\n",
    "\n",
    "feat_backward = list(sfs_backward.k_feature_names_)\n",
    "print(\"Características seleccionadas (Backward desde Forward):\", feat_backward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b053eea-1a11-486f-9c4c-605e84c43c4d",
   "metadata": {},
   "source": [
    "EXPLICACION SEIS: Filtramos Xtrain y Xtest para quedarnos solo con las columnas que pasaron al proceso de Backward, esto reduce la dimensión del problema al mejor conjunto.\n",
    "Reestimamos los coeficientes con el subespacio final. fit() vuelve a resolver mínimos cuadrados, pero ahora en el espacio de características reducido.\n",
    "Predecimos en test con el modelo compacto, usando el mismo orden y las mismas columnas que en el entrenamiento.\n",
    "Por último medimos la generalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3cafbefd-3a5a-4616-9b5f-49428e79ee20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² del modelo Backward: 0.45304512202438574\n"
     ]
    }
   ],
   "source": [
    "XtrainBackward = Xtrain[feat_backward]\n",
    "XtestBackward  = Xtest[feat_backward]\n",
    "\n",
    "linearR.fit(XtrainBackward, ytrain)\n",
    "ypredBackward = linearR.predict(XtestBackward)\n",
    "\n",
    "r2Backward = r2_score(ytest, ypredBackward)\n",
    "print(\"R² del modelo Backward:\", r2Backward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
